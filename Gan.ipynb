{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCu9icWKs9S2yYMpUe98t8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borundev/pytorch_lightning_examples/blob/decouple_gan_generator_discriminator/Gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDBqqAmqkJAZ"
      },
      "source": [
        "!pip install -Uqq pytorch_lightning\n",
        "!pip install -Uqq pytorch-lightning-bolts\n",
        "!pip install -Uqq wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqTq8XWokOnT"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "from pl_bolts.datamodules.cifar10_datamodule import CIFAR10DataModule\n",
        "from torch import nn\n",
        "import torch\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import numpy as np\n",
        "import torchvision.utils as vutils\n",
        "import wandb\n",
        "import torchvision\n",
        "import psutil\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwDfRfxkFbti"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, img_shape):\n",
        "        super().__init__()\n",
        "        self.latent_dim=latent_dim\n",
        "        self.img_shape=img_shape\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_shape):\n",
        "        super().__init__()\n",
        "        self.img_shape=img_shape\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)\n",
        "\n",
        "class LambdaModule(nn.Module):\n",
        "    def __init__(self, lambd):\n",
        "        super().__init__()\n",
        "        import types\n",
        "        assert type(lambd) is types.LambdaType\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwdRsWeCFoCe"
      },
      "source": [
        "class GeneratorDCGAN(Generator):\n",
        "    def __init__(self, latent_dim, img_shape,ngf=64):\n",
        "        super().__init__(latent_dim, img_shape)\n",
        "        nc=img_shape[0]\n",
        "        self.model = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            LambdaModule(lambda x: x.unsqueeze(-1).unsqueeze(-1)),\n",
        "            nn.ConvTranspose2d( latent_dim, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            #nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.ConvTranspose2d(ngf*2, nc, 4, 2, 1, bias=False),\n",
        "            #nn.BatchNorm2d(ngf),\n",
        "            #nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            #nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    # custom weights initialization called on netG and netD\n",
        "    @staticmethod\n",
        "    def weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv') != -1:\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        elif classname.find('BatchNorm') != -1:\n",
        "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "            nn.init.constant_(m.bias.data, 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2KbXA-VFF6z"
      },
      "source": [
        "class DiscriminatorDCGAN(Discriminator):\n",
        "    def __init__(self, img_shape ,ndf = 64,):\n",
        "        super().__init__(img_shape)\n",
        "        nc=img_shape[0]\n",
        "        self.model = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            #nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            #nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            #nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.Conv2d(nc, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Flatten(1)\n",
        "        )\n",
        "        self.apply(self.weights_init)\n",
        "\n",
        "\n",
        "    # custom weights initialization called on netG and netD\n",
        "    @staticmethod\n",
        "    def weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv') != -1:\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        elif classname.find('BatchNorm') != -1:\n",
        "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "            nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eNcv2LrGJJ3"
      },
      "source": [
        "class GAN(pl.LightningModule):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            channels,\n",
        "            width,\n",
        "            height,\n",
        "            generator,\n",
        "            discriminator,\n",
        "            latent_dim: int = 100,\n",
        "            lr: float = 0.0002,\n",
        "            b1: float = 0.5,\n",
        "            b2: float = 0.999,\n",
        "            batch_size: int = 64,\n",
        "            **kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # networks\n",
        "        self.data_shape = (channels, width, height)\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "\n",
        "        self.fixed_random_sample = None\n",
        "\n",
        "    def print_summary(self):\n",
        "        print(torchsummary.summary(self.generator, (self.hparams.latent_dim,), 1))\n",
        "        print(torchsummary.summary(self.discriminator, self.data_shape, 1))\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.generator(z)\n",
        "\n",
        "    def adversarial_loss(self, y_hat, y):\n",
        "        return F.binary_cross_entropy(y_hat, y)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "\n",
        "        # if this is the first run make the fixed random vector\n",
        "        if self.fixed_random_sample is None:\n",
        "            imgs, _ = batch\n",
        "            self.fixed_random_sample = torch.randn(6, self.hparams.latent_dim,device=self.device)\n",
        "\n",
        "        # log images generatd from fixed random noise status of the fixed random noise generated images\n",
        "        sample_imgs = self(self.fixed_random_sample)\n",
        "        grid = torchvision.utils.make_grid(sample_imgs,padding=2, normalize=True).detach().cpu().numpy().transpose(1, 2, 0)\n",
        "        self.logger.experiment.log(\n",
        "            {'gen_images': [wandb.Image(grid, caption='{}:{}'.format(self.current_epoch, batch_idx))]}, commit=False)\n",
        "\n",
        "        process = psutil.Process(os.getpid())\n",
        "        self.log('memory',process.memory_info().rss/(1024**3))\n",
        "\n",
        "        if optimizer_idx == 0:\n",
        "            return self.training_step_generator(batch, batch_idx)\n",
        "        elif optimizer_idx == 1:\n",
        "            return self.training_step_discriminator(batch, batch_idx)\n",
        "\n",
        "    def training_step_generator(self, batch, batch_idx):\n",
        "\n",
        "        imgs, _ = batch\n",
        "        batch_size = imgs.shape[0]\n",
        "\n",
        "        # note z.type_as(imgs) not only type_casts but also puts on the same device\n",
        "        z = torch.randn(batch_size, self.hparams.latent_dim,device=self.device)\n",
        "        generated_imgs = self(z)\n",
        "        generated_y_score = self.discriminator(generated_imgs)\n",
        "        generated_y = torch.ones(imgs.size(0), 1,device=self.device)\n",
        "        g_loss = self.adversarial_loss(generated_y_score, generated_y)\n",
        "\n",
        "        fooling_fraction = (generated_y_score > 0.5).type(torch.float).flatten().mean()\n",
        "\n",
        "        self.log('generator/g_loss', g_loss, prog_bar=True)\n",
        "        self.log('generator/g_fooling_fraction', fooling_fraction, prog_bar=True)\n",
        "\n",
        "        return {'loss': g_loss}\n",
        "\n",
        "    def training_step_discriminator(self, batch, batch_idx):\n",
        "        imgs, _ = batch\n",
        "        batch_size = imgs.shape[0]\n",
        "\n",
        "        # note z.type_as(imgs) not only type_casts but also puts on the same device\n",
        "        z = torch.randn(batch_size, self.hparams.latent_dim,device=self.device)\n",
        "        generated_imgs = self(z)\n",
        "        generated_y_score = self.discriminator(generated_imgs)\n",
        "        generated_y = torch.zeros(imgs.size(0), 1,device=self.device)\n",
        "        generated_loss = self.adversarial_loss(generated_y_score, generated_y)\n",
        "\n",
        "        real_y_score = self.discriminator(imgs)\n",
        "        real_y = torch.ones(imgs.size(0), 1,device=self.device)\n",
        "        real_loss = self.adversarial_loss(real_y_score, real_y)\n",
        "\n",
        "        y_score = torch.cat([real_y_score, generated_y_score], 0)\n",
        "        y = torch.cat([real_y, generated_y], 0)\n",
        "        pred = (y_score > 0.5).type(torch.int).view(-1, 1)\n",
        "\n",
        "        accuracy = (pred == y).type(torch.float).mean()\n",
        "        loss = (real_loss + generated_loss) / 2.0\n",
        "\n",
        "        self.log('discriminator/d_loss', loss, prog_bar=True)\n",
        "        self.log('discriminator/d_accuracy', accuracy, prog_bar=True)\n",
        "\n",
        "        return {'loss': loss,\n",
        "                'y_score': y_score.cpu().detach().numpy(),\n",
        "                'y': y.detach().cpu().numpy()\n",
        "                }\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        discriminator_score = []\n",
        "        discriminator_y = []\n",
        "\n",
        "        for output in outputs[1]:\n",
        "            discriminator_y.append(output['y'])\n",
        "            discriminator_score.append(output['y_score'])\n",
        "        discriminator_score = np.concatenate(discriminator_score)\n",
        "        discriminator_y = np.concatenate(discriminator_y)\n",
        "        discriminator_score = np.concatenate([1 - discriminator_score, discriminator_score], 1)\n",
        "\n",
        "        y_true = discriminator_y.flatten()\n",
        "        y_score = discriminator_score\n",
        "\n",
        "        #self.log(\"discriminator/discriminator_pr\", wandb.plot.pr_curve(y_true, y_score, labels=['Fake', 'Real']))\n",
        "        #self.log(\"discriminator/discriminator_roc\", wandb.plot.roc_curve(y_true, y_score, labels=['Fake', 'Real']))\n",
        "        self.log('discriminator/discriminator_confusion_matrix', wandb.plot.confusion_matrix(y_score,\n",
        "                                                                                             y_true,\n",
        "                                                                                             class_names=['Fake',\n",
        "                                                                                                          'Real']))\n",
        "\n",
        "        p, r, t = precision_recall_curve(1-y_true, y_score[:, 0])\n",
        "        plt.plot(r,p,label='Fake')\n",
        "        p, r, t = precision_recall_curve(y_true, y_score[:, 1])\n",
        "        plt.plot(r,p, label='Real')\n",
        "        plt.xlim(0,1)\n",
        "        plt.ylim(0,1)\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        self.log('discriminator/pr_curve',wandb.Image(plt,caption='Epoch: {}'.format(self.current_epoch)))\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        lr = self.hparams.lr\n",
        "        b1 = self.hparams.b1\n",
        "        b2 = self.hparams.b2\n",
        "\n",
        "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "        return [opt_g, opt_d], []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yeJl_yn40ZS"
      },
      "source": [
        "Generator=GeneratorDCGAN\n",
        "Discriminator=DiscriminatorDCGAN\n",
        "DataModule=CIFAR10DataModule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izOiZJCP42u9"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYF32fLi46uM"
      },
      "source": [
        "dm = DataModule('.')\n",
        "latent_dim=100\n",
        "img_shape=dm.size()\n",
        "\n",
        "generator=Generator(latent_dim=latent_dim, img_shape=img_shape)\n",
        "discriminator=Discriminator(img_shape=img_shape)\n",
        "\n",
        "model = GAN(*dm.size(),latent_dim=latent_dim, generator=generator, discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qc_r7ZK5A9U"
      },
      "source": [
        "logger = WandbLogger(project='gan_memory_profiling',name='colab-gpu')\n",
        "\n",
        "dm.prepare_data()\n",
        "dm.setup()\n",
        "dataloader =dm.train_dataloader()\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "gpus=1\n",
        "device = 'cuda:0'\n",
        "\n",
        "\n",
        "real_images=np.transpose(vutils.make_grid(real_batch[0][:6], padding=2, normalize=True).detach().numpy(),(1,2,0))\n",
        "logger.experiment.log({'real_sample':[wandb.Image(real_images, caption='Real Images')]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYVKgl2293nC"
      },
      "source": [
        "trainer = pl.Trainer(gpus=gpus,\n",
        "                     max_epochs=3,\n",
        "                     logger=logger,\n",
        "                     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0veooVk1GgQ-"
      },
      "source": [
        "trainer.fit(model, dm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Netsd3ZpJ2DG"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNKZV_nHKP1w"
      },
      "source": [
        "logger = WandbLogger(project='gan_memory_profiling',name='colab-cpu')\n",
        "\n",
        "dm.prepare_data()\n",
        "dm.setup()\n",
        "dataloader =dm.train_dataloader()\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "gpus=0\n",
        "device = 'cpu'\n",
        "\n",
        "\n",
        "real_images=np.transpose(vutils.make_grid(real_batch[0][:6], padding=2, normalize=True).detach().numpy(),(1,2,0))\n",
        "logger.experiment.log({'real_sample':[wandb.Image(real_images, caption='Real Images')]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2lIiHHuLjro"
      },
      "source": [
        "trainer = pl.Trainer(gpus=gpus,\n",
        "                     max_epochs=3,\n",
        "                     logger=logger,\n",
        "                     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6_pONlvLqYx"
      },
      "source": [
        "generator=Generator(latent_dim=latent_dim, img_shape=img_shape)\n",
        "discriminator=Discriminator(img_shape=img_shape)\n",
        "\n",
        "model = GAN(*dm.size(),latent_dim=latent_dim, generator=generator, discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKX_i11MLtko"
      },
      "source": [
        "trainer.fit(model, dm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNsD3NqoMADt"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47dwdAQIMoo0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}