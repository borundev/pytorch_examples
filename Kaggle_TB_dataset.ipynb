{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle TB dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfYfAqhYiw6lqiZfckgb3S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borundev/pytorch_examples/blob/kaggle-dataset/Kaggle_TB_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRc64THkrNae"
      },
      "source": [
        "!pip install -Uqq --no-cache-dir --upgrade git+https://github.com/borundev/pytorch_examples@kaggle-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_5pI0XKrZtl"
      },
      "source": [
        "from data.kaggle.tb_xrays import TBDataModule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQwi4pfLsJxP"
      },
      "source": [
        "kaggle_username=input('kaggle_username: ')\n",
        "kaggle_key=input('kaggle_key: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knuD8xYwrypz"
      },
      "source": [
        "try:\n",
        "  dm = TBDataModule(kaggle_username=kaggle_username, \n",
        "                  kaggle_key=kaggle_key,\n",
        "                  )\n",
        "except NameError:\n",
        "  dm = TBDataModule()\n",
        "\n",
        "dm.prepare_data()\n",
        "dm.setup()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-PwkXCYsyTK"
      },
      "source": [
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27iSd9sUr3Tx"
      },
      "source": [
        "imgs,labels = next(iter(dm.train_dataloader()))\n",
        "plt.imshow(torchvision.utils.make_grid(imgs[:16],normalize=True).permute(1,2,0))\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP_qsFbFs0oK"
      },
      "source": [
        "import pytorch_lightning as pl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaLT0ON_uD-W"
      },
      "source": [
        "from pytorch_lightning.loggers import WandbLogger\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgcDK1Xyw5hN"
      },
      "source": [
        "class BoilerPlate(pl.LightningModule):\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def loss(inp, y):\n",
        "        \"\"\"\n",
        "        Since pytorch doesn't have a one-hot version of cross entropy we implement it here\n",
        "        :param inp:\n",
        "        :param y:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        lsm = nn.LogSoftmax(1)\n",
        "        yp = torch.stack([1 - y, y], 1)\n",
        "        return -torch.mean(torch.sum(yp * lsm(inp), 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return NotImplementedError()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        outputs = self(x)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = self.loss(outputs, y)\n",
        "        accuracy = (preds == y.data).type(torch.float32).mean()\n",
        "        self.log('train/loss', loss)\n",
        "        self.log('train/accuracy', accuracy)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        outputs = self(x)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = self.loss(outputs, y)\n",
        "        accuracy=(preds == y.data).type(torch.float32).mean()\n",
        "        self.log('val/loss', loss)\n",
        "        self.log('val/accuracy', accuracy)\n",
        "        return y,outputs\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "\n",
        "        ground_truths, predictions = zip(*outputs)\n",
        "        predictions=torch.nn.Softmax(1)(torch.cat(predictions)).cpu().numpy()\n",
        "        ground_truths=torch.cat(ground_truths).cpu().numpy().astype(np.int)\n",
        "\n",
        "        self.log(\"pr\", wandb.plot.pr_curve(ground_truths, predictions,\n",
        "                                                labels=['Normal','Tuberculosis']))\n",
        "        self.log(\"roc\", wandb.plot.roc_curve(ground_truths, predictions,\n",
        "                                                labels=['Normal','Tuberculosis']))\n",
        "        self.log('confusion_matrix',wandb.plot.confusion_matrix(predictions,\n",
        "                                    ground_truths,class_names=['Normal','Tuberculosis']))\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        outputs = self(x)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = self.loss(outputs, y)\n",
        "        accuracy=(preds == y.data).type(torch.float32).mean()\n",
        "        self.log('test/loss', loss)\n",
        "        self.log('test/accuracy', accuracy)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        NotImplementedError\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw_HBxujxnZD"
      },
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class CustomModel(BoilerPlate):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        model_ft = models.resnet152(pretrained=True)\n",
        "        for param in model_ft.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        # Here the size of each output sample is set to 2.\n",
        "        # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "        model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "        self.model = model_ft\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.SGD(self.model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "        return optimizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zonVlgZiulGm"
      },
      "source": [
        "import wandb\n",
        "wandb_logger = WandbLogger(project='TB Dataset Kaggle')\n",
        "trainer = pl.Trainer(\n",
        "        gpus=1,\n",
        "        max_epochs=5,\n",
        "        logger=wandb_logger,\n",
        "        progress_bar_refresh_rate=50,\n",
        "        )\n",
        "model = CustomModel()\n",
        "trainer.fit(model, dm)\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY-SlV2c0ej7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}